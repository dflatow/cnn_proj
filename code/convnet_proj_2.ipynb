{
 "metadata": {
  "name": "",
  "signature": "sha256:1fb52dc68a8fa43d24ce4af6e52105ed643a7b7309300477270f6effbbf87f53"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Train a ConvNet!\n",
      "We now have a generic solver and a bunch of modularized layers. It's time to put it all together, and train a ConvNet to recognize the classes in CIFAR-10. In this notebook we will walk you through training a simple two-layer ConvNet and then set you free to build the best net that you can to perform well on CIFAR-10.\n",
      "\n",
      "Open up the file `cs231n/classifiers/convnet.py`; you will see that the `two_layer_convnet` function computes the loss and gradients for a two-layer ConvNet. Note that this function uses the \"sandwich\" layers defined in `cs231n/layer_utils.py`. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# As usual, a bit of setup\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from cs231n.classifier_trainer import ClassifierTrainer\n",
      "from cs231n.gradient_check import eval_numerical_gradient\n",
      "from cs231n.classifiers.convnet_final import *\n",
      "import cPickle as pickle\n",
      "import os\n",
      "\n",
      "%matplotlib inline\n",
      "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
      "plt.rcParams['image.interpolation'] = 'nearest'\n",
      "plt.rcParams['image.cmap'] = 'gray'\n",
      "\n",
      "# for auto-reloading external modules\n",
      "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "\n",
      "def rel_error(x, y):\n",
      "  \"\"\" returns relative error \"\"\"\n",
      "  return np.max(np.abs(x - y) / (np.maximum(1e-18, np.abs(x) + np.abs(y))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The autoreload extension is already loaded. To reload it, use:\n",
        "  %reload_ext autoreload\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from cs231n.data_utils import load_CIFAR10\n",
      "\n",
      "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000):\n",
      "    \"\"\"\n",
      "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
      "    it for the two-layer neural net classifier. These are the same steps as\n",
      "    we used for the SVM, but condensed to a single function.  \n",
      "    \"\"\"\n",
      "    # Load the raw CIFAR-10 data\n",
      "    cifar10_dir = '/Users/daflatow/Dropbox/Stanford/CS231N/assignments/assignment2_submitted/cs231n/datasets/cifar-10-batches-py'\n",
      "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
      "        \n",
      "    # Subsample the data\n",
      "    mask = range(num_training, num_training + num_validation)\n",
      "    X_val = X_train[mask]\n",
      "    y_val = y_train[mask]\n",
      "    mask = range(num_training)\n",
      "    X_train = X_train[mask]\n",
      "    y_train = y_train[mask]\n",
      "    mask = range(num_test)\n",
      "    X_test = X_test[mask]\n",
      "    y_test = y_test[mask]\n",
      "\n",
      "    # Normalize the data: subtract the mean image\n",
      "    mean_image = np.mean(X_train, axis=0)\n",
      "    X_train -= mean_image\n",
      "    X_val -= mean_image\n",
      "    X_test -= mean_image\n",
      "    \n",
      "    # Transpose so that channels come first\n",
      "    X_train = X_train.transpose(0, 3, 1, 2).copy()\n",
      "    X_val = X_val.transpose(0, 3, 1, 2).copy()\n",
      "    x_test = X_test.transpose(0, 3, 1, 2).copy()\n",
      "\n",
      "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
      "\n",
      "\n",
      "# Invoke the above function to get our data.\n",
      "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data()\n",
      "print 'Train data shape: ', X_train.shape\n",
      "print 'Train labels shape: ', y_train.shape\n",
      "print 'Validation data shape: ', X_val.shape\n",
      "print 'Validation labels shape: ', y_val.shape\n",
      "print 'Test data shape: ', X_test.shape\n",
      "print 'Test labels shape: ', y_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train data shape:  (49000, 3, 32, 32)\n",
        "Train labels shape:  (49000,)\n",
        "Validation data shape:  (1000, 3, 32, 32)\n",
        "Validation labels shape:  (1000,)\n",
        "Test data shape:  (1000, 32, 32, 3)\n",
        "Test labels shape:  (1000,)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# PERMUTE LABELS!\n",
      "def permute_lables(p, labels_orig, classes=9): \n",
      "    labels = labels_orig.copy()\n",
      "    n_labels = len(labels)\n",
      "    n_to_permute = int(np.floor(p * n_labels))\n",
      "    inds_to_permute = np.random.choice(n_labels, n_to_permute, replace=False)\n",
      "    new_labels = np.random.choice(classes, n_to_permute, replace=True)\n",
      "    labels[inds_to_permute] = new_labels\n",
      "    return labels\n",
      "  \n",
      "p = 0.10\n",
      "y_train_permuted = permute_lables(p, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Use a three-layer ConvNet to do really well on CIFAR-10!\n",
      "model = init_three_layer_convnet(filter_size=5, weight_scale=5e-3, num_filters=32)\n",
      "trainer = ClassifierTrainer()\n",
      "best_model, loss_history, train_acc_history, val_acc_history = trainer.train(\n",
      "          X_train, y_train_permuted, X_val, y_val, model, three_layer_convnet, update='momentum',\n",
      "          reg=0.00008, momentum=0.9, learning_rate=0.0014, batch_size=300, num_epochs=60,\n",
      "          verbose=True) #0.1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finished epoch 0 / 60: cost 2.301055, train: 0.107000, val 0.095000, lr 1.400000e-03\n",
        "Finished epoch 1 / 60: cost 1.578974, train: 0.492000, val 0.553000, lr 1.330000e-03"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished epoch 2 / 60: cost 1.280368, train: 0.561000, val 0.579000, lr 1.263500e-03"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished epoch 3 / 60: cost 1.459395, train: 0.609000, val 0.621000, lr 1.200325e-03"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished epoch 4 / 60: cost 1.129773, train: 0.631000, val 0.641000, lr 1.140309e-03"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished epoch 5 / 60: cost 1.279664, train: 0.638000, val 0.655000, lr 1.083293e-03"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished epoch 6 / 60: cost 1.314254, train: 0.645000, val 0.674000, lr 1.029129e-03"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished epoch 7 / 60: cost 1.132637, train: 0.680000, val 0.688000, lr 9.776722e-04"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished epoch 8 / 60: cost 1.206170, train: 0.673000, val 0.664000, lr 9.287886e-04"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished epoch 9 / 60: cost 1.093621, train: 0.679000, val 0.679000, lr 8.823492e-04"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished epoch 10 / 60: cost 1.015605, train: 0.691000, val 0.661000, lr 8.382317e-04"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished epoch 11 / 60: cost 0.920037, train: 0.685000, val 0.672000, lr 7.963201e-04"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished epoch 12 / 60: cost 0.989491, train: 0.718000, val 0.680000, lr 7.565041e-04"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished epoch 13 / 60: cost 0.938352, train: 0.721000, val 0.688000, lr 7.186789e-04"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished epoch 14 / 60: cost 0.968724, train: 0.743000, val 0.697000, lr 6.827450e-04"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished epoch 15 / 60: cost 0.854826, train: 0.746000, val 0.688000, lr 6.486077e-04"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished epoch 16 / 60: cost 0.900689, train: 0.732000, val 0.685000, lr 6.161773e-04"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished epoch 17 / 60: cost 0.840995, train: 0.757000, val 0.665000, lr 5.853685e-04"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished epoch 18 / 60: cost 0.775693, train: 0.758000, val 0.689000, lr 5.561000e-04"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished epoch 19 / 60: cost 0.936767, train: 0.715000, val 0.684000, lr 5.282950e-04"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished epoch 20 / 60: cost 0.927592, train: 0.738000, val 0.680000, lr 5.018803e-04"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished epoch 21 / 60: cost 0.792385, train: 0.744000, val 0.676000, lr 4.767863e-04"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished epoch 22 / 60: cost 0.847837, train: 0.765000, val 0.679000, lr 4.529470e-04"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished epoch 23 / 60: cost 0.683275, train: 0.780000, val 0.661000, lr 4.302996e-04"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished epoch 24 / 60: cost 0.892048, train: 0.774000, val 0.665000, lr 4.087846e-04"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished epoch 25 / 60: cost 0.720694, train: 0.757000, val 0.655000, lr 3.883454e-04"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-11-c6b4cdb432f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_permuted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthree_layer_convnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'momentum'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mreg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00008\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0014\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           verbose=True)\n\u001b[0m",
        "\u001b[0;32m/Users/daflatow/Dropbox/Stanford/CS231N/assignments/assignment2_submitted/cs231n/classifier_trainer.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y, X_val, y_val, model, loss_function, reg, learning_rate, momentum, learning_rate_decay, update, sample_batches, num_epochs, batch_size, acc_frequency, verbose)\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0msample_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mbatch_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best_model_file = 'best_conv_net.p'\n",
      "with open(best_model_file) as f:\n",
      "    best_model = pickle.load(f)\n",
      "        \n",
      "grid = visualize_grid(best_model['W1'].transpose(0, 2, 3, 1))\n",
      "plt.imshow(grid.astype('uint8'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "<matplotlib.image.AxesImage at 0x105df5a10>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAdwAAAHaCAYAAACq+vjoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFC4AABlQuAAAZEDhAgCQwf8Dx2uGXDKsMhIAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x105d11750>"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best_model_file = 'best_conv_net.p'\n",
      "with open(best_model_file) as f:\n",
      "    best_model = pickle.load(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores_test = three_layer_convnet(X_test.transpose(0, 3, 1, 2), best_model)\n",
      "print 'Test accuracy: ', np.mean(np.argmax(scores_test, axis=1) == y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Test accuracy:  0.739\n"
       ]
      }
     ],
     "prompt_number": 33
    }
   ],
   "metadata": {}
  }
 ]
}